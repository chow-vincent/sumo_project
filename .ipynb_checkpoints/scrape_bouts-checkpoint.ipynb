{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Bouts by Opponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim to Obtain Head-to-Head Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.705609881626351"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO:\n",
    "# - should I change to storing full shikona name from rikishi_df?\n",
    "# - or just make note that shikona is shortened in h2h_df?\n",
    "\n",
    "profiles = 7771\n",
    "des_time = 8*60*60 # [sec]\n",
    "float(des_time)/float(profiles)\n",
    "\n",
    "# if 4 hrs desired, 1.85 sec/profile\n",
    "# if 8 hrs desired, 3.7 s/profile\n",
    "# if 16 hrs desired, 7.4 s/profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.5861111111\n"
     ]
    }
   ],
   "source": [
    "current_rate = 10 # s/profile\n",
    "profiles = 7771\n",
    "est_time = float(current_rate*profiles)/float(3600)\n",
    "print est_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import bs4\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "from rikishi_scrape import shikona_scrape\n",
    "from data_extraction import extract_bout_title_tags\n",
    "from database_ops import match_ID\n",
    "\n",
    "rikishi_df = pd.read_pickle('data/all_rikishi.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rikishi 1 URL Access: 3.71508789062\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# setup beautiful soup\n",
    "rikishi = \"http://sumodb.sumogames.de/Rikishi_opp.aspx?r=1123\"  # hakuho h2h page\n",
    "# rikishi = \"http://sumodb.sumogames.de/Rikishi_opp.aspx?r=11893\" # Akashi (no bouts)\n",
    "start = time.time()\n",
    "source = urllib2.urlopen(rikishi).read()\n",
    "end = time.time()\n",
    "print \"Rikishi 1 URL Access: \" + str(end-start)\n",
    "\n",
    "soup = bs4.BeautifulSoup(source, 'lxml')  # turn into soup\n",
    "print 'done'\n",
    "\n",
    "# head2head record containing rikishi names and win-loss data are located in \"spans\" in html\n",
    "h2h_records = soup.findAll('span', {'class': 'rb_basho'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test match_ID helper fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shikona = u'Oga'\n",
    "heya = u'Takasago'\n",
    "birth_date = u'22.10.1977'\n",
    "hatsu_dohyo = u'1993.03'\n",
    "intai = u''\n",
    "bday = datetime.strptime(birth_date, '%d.%m.%Y')\n",
    "debut = datetime.strptime(hatsu_dohyo, '%Y.%m')\n",
    "# retirement = datetime.strptime(intai, '%d.%m.%Y')\n",
    "\n",
    "logical = rikishi_df['shikona'].map(lambda x: x is not None) & \\\n",
    "            rikishi_df['sumo_stable'].map(lambda x: x is not None) & \\\n",
    "            rikishi_df['bday'].map(lambda x: x is not None) & \\\n",
    "            rikishi_df['debut'].map(lambda x: x is not None)\n",
    "filtered_df = rikishi_df[logical]\n",
    "    \n",
    "rikishi_url = \"http://sumodb.sumogames.de/Rikishi.aspx?r=247\"\n",
    "ID, speed = match_ID(shikona, heya, bday, debut, filtered_df, rikishi_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28      28\n",
       "33      33\n",
       "469    469\n",
       "645    645\n",
       "665    665\n",
       "Name: rikishi_ID, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical = rikishi_df['shikona'].map(lambda x: x is not None) & \\\n",
    "            rikishi_df['sumo_stable'].map(lambda x: x is not None) & \\\n",
    "            rikishi_df['bday'].map(lambda x: x is not None) & \\\n",
    "            rikishi_df['debut'].map(lambda x: x is not None)\n",
    "filtered_df = rikishi_df.loc[logical, 'rikishi_ID']\n",
    "filtered_df.head()\n",
    "# 7721 profiles satisfy the fact that shikona, bday, and debut exist (dating back to 1713)\n",
    "# should be safe assumption that if info exists in a href tag, it should exist in sumo basic profile page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over Rikishi Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akiasahi\n",
      "Ako\n",
      "Aminishiki\n",
      "Aoiyama\n",
      "Aran\n",
      "Aranonami\n",
      "Arawashi\n",
      "Asairyu\n",
      "Asanowaka\n",
      "Asasekiryu\n",
      "Asashoryu\n",
      "Asatofuji\n",
      "Azumadake\n",
      "Baruto\n",
      "Bushuyama\n",
      "Buyuzan\n",
      "Chiyootori\n",
      "Chiyotaikai\n",
      "Chiyotairyu\n",
      "Daihoyama\n",
      "Daimanazuru\n",
      "Daionami\n",
      "Dairaido\n",
      "Daishochi\n",
      "Daishoma\n",
      "Daitenzan\n",
      "Dejima\n",
      "Dewanofuji\n",
      "Endo\n",
      "Fujinoshima\n",
      "Fukuseyama\n",
      "Furuichi\n",
      "Furukawa\n",
      "Futeno\n",
      "Gagamaru\n",
      "Goeido\n",
      "Gojoro\n",
      "Hakuba\n",
      "Hakurozan\n",
      "Hamamoto\n",
      "Hamanishiki\n",
      "Harumafuji\n",
      "Harunoyama\n",
      "Hayashi\n",
      "Hayateumi\n",
      "Hiranoyama\n",
      "Hisanohana\n",
      "Hokutonada\n",
      "Hokutoriki\n",
      "Hokutosho\n",
      "Homasho\n",
      "Hoshitango\n",
      "Ichinojo\n",
      "Ichinotani\n",
      "Ieda\n",
      "Ikioi\n",
      "Iwakiyama\n",
      "Jokoryu\n",
      "Juzan\n",
      "Kaido\n",
      "Kaiho\n",
      "Kaio\n",
      "Kaisei\n",
      "Kakizoe\n",
      "Kakuryu\n",
      "Kanaya\n",
      "Kasugakuni\n",
      "Kasuganami\n",
      "Kasugao\n",
      "Katayama\n",
      "Kimenryu\n",
      "Kinkaiyama\n",
      "Kinoshita\n",
      "Kirinofuji\n",
      "Kirinoumi\n",
      "Kisenosato\n",
      "Kisomitsuru\n",
      "Kitakasuga\n",
      "Kitataiki\n",
      "Kodama\n",
      "Kokkai\n",
      "Koryuyama\n",
      "Koshinoryu\n",
      "Koshinoyama\n",
      "Kotomitsuki\n",
      "Kotonomine\n",
      "Kotonowaka\n",
      "Kotooshu\n",
      "Kotoshogiku\n",
      "Kotoyuki\n",
      "Kubota\n",
      "Kuniazuma\n",
      "Kyokuhikari\n",
      "Kyokushuzan\n",
      "Kyokutenho\n",
      "Maenowaka\n",
      "Masutsuyoshi\n",
      "Midorifuji\n",
      "Minaminoshima\n",
      "Misugikuni\n",
      "Mitakeumi\n",
      "Miyabiyama\n",
      "Murata\n",
      "Musoyama\n",
      "Myogiryu\n",
      "Nakabuchi\n",
      "Nakao\n",
      "Natsubori\n",
      "Nishisegawa\n",
      "Oga\n",
      "Oginishiki\n",
      "Ohidake\n",
      "Okinoumi\n",
      "Okoyama\n",
      "Ominami\n",
      "Onochikara\n",
      "Orora\n",
      "Oseumi\n",
      "Osunaarashi\n",
      "Raiko\n",
      "Roho\n",
      "Ryuho\n",
      "Ryukiyama\n",
      "Sadanoumi\n",
      "Shimotori\n",
      "Shindo\n",
      "Shodai\n",
      "Shohozan\n",
      "Shoji\n",
      "Shotenro\n",
      "Sumanofuji\n",
      "Suzukawa\n",
      "Taiga\n",
      "Taiyo\n",
      "Takafurukawa\n",
      "Takahijiri\n",
      "Takakoyama\n",
      "Takamaru\n",
      "Takamihana\n",
      "Takamisakari\n",
      "Takanoiwa\n",
      "Takanotsuru\n",
      "Takanoumi\n",
      "Takanowaka\n",
      "Takao\n",
      "Takarafuji\n",
      "Takayasu\n",
      "Takekaze\n",
      "Takinooto\n",
      "Tamaaoi\n",
      "Tamakasuga\n",
      "Tamanoshima\n",
      "Tamatsurugi\n",
      "Tamawashi\n",
      "Tatsuyutaka\n",
      "Tenichi\n",
      "Terukaze\n",
      "Terunofuji\n",
      "Tetsuhikari\n",
      "Tochiazuma\n",
      "Tochifudo\n",
      "Tochinohana\n",
      "Tochinonada\n",
      "Tochinoshin\n",
      "Tochinowaka\n",
      "Tochiozan\n",
      "Tochisakae\n",
      "Tochitaiho\n",
      "Tokinoboru\n",
      "Tokitenku\n",
      "Tokitsukasa\n",
      "Tokitsuumi\n",
      "Tokusegawa\n",
      "Tokushoryu\n",
      "Tosanoumi\n",
      "Tosayutaka\n",
      "Toshinyama\n",
      "Towanoyama\n",
      "Toyohibiki\n",
      "Toyonoshima\n",
      "Toyozakura\n",
      "Tsurunosho\n",
      "Uchigoshiki\n",
      "Wakakosho\n",
      "Wakakoyu\n",
      "Wakanoho\n",
      "Wakanosato\n",
      "Wakanoyama\n",
      "Wakashinobu\n",
      "Wakataizan\n",
      "Wakatenro\n",
      "Yamane\n",
      "Yamasaki\n",
      "Yoshiazuma\n",
      "Yoshikaze\n",
      "\n",
      "# --- SCRAPING DONE --- #\n",
      "Execution Time: 2.60 (s)\n"
     ]
    }
   ],
   "source": [
    "# initialize data storage\n",
    "data_rows = []  # list of dictionaries, where each dict is a row in df\n",
    "\n",
    "shikona1 = u'Hakuho Sho'  # assume we already have this b/c we entered rikishi bout page from rikishi profile\n",
    "ID1 = u'11878'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# setup filtered_df\n",
    "# 7722 profiles satisfy the fact that shikona, bday, and debut exist (dating back to 1713)\n",
    "logical = rikishi_df['shikona'].map(lambda x: x is not None) & \\\n",
    "          rikishi_df['sumo_stable'].map(lambda x: x is not None) & \\\n",
    "          rikishi_df['bday'].map(lambda x: pd.notnull(x)) & \\\n",
    "          rikishi_df['debut'].map(lambda x: pd.notnull(x))\n",
    "filtered_df = rikishi_df[logical]\n",
    "# --- Loop Over Records --- #\n",
    "\n",
    "timer = []\n",
    "for record in h2h_records:\n",
    "    \n",
    "    data_dict = {}  # initialize a dict to store one row of df\n",
    "    \n",
    "    # initialize variables\n",
    "    ID2 = u''\n",
    "    wins1 = None\n",
    "    playoff_wins1 = None\n",
    "    fusen_wins1 = None\n",
    "    wins2 = None\n",
    "    playoff_wins2 = None\n",
    "    fusen_wins2 = None\n",
    "    flag = False  # turn on flag if there is inconsistency in data\n",
    "    \n",
    "    \n",
    "    # --- Extract Tag Info --- #\n",
    "    span_text = record.findAll(text=True)  # get all text in span tag\n",
    "    links = record.findAll('a', href=True)  # one row\n",
    "    ext = links[1]['href']  # only extract second link (2nd rikishi)\n",
    "    rikishi_title = links[1]['title']  # extract title attribute text\n",
    "    rikishi_url = \"http://sumodb.sumogames.de/\" + ext\n",
    "    \n",
    "    # --- Find Rikishi ID --- #\n",
    "    # get title info from 2nd rikishi\n",
    "    shikona2 = span_text[2]\n",
    "    print shikona2\n",
    "    heya, bday, debut = extract_bout_title_tags(rikishi_title)\n",
    "      \n",
    "    ID2, speed = match_ID(shikona2, heya, bday, debut, filtered_df, rikishi_url)\n",
    "    timer.append(speed)\n",
    "\n",
    "    # --- Extract Head-to-Head Data --- #\n",
    "    raw_h2h = span_text[len(span_text)-1]  # index into last piece of text of title\n",
    "    h2h = unicode(raw_h2h.string).strip()  # strip leading/ending whitespace, convert to unicode\n",
    "\n",
    "    reg_exp = re.compile('^(\\d+)(\\[\\+\\d+\\])?(\\[-\\d+\\])?-(\\d+)(\\[\\+\\d+\\])?(\\[-\\d+\\])?(?:-.+)?$')\n",
    "\n",
    "    h2h_result = reg_exp.match(h2h)\n",
    "    if h2h_result:\n",
    "        h2h_data = h2h_result.groups()\n",
    "\n",
    "        try:\n",
    "            wins1 = int(h2h_data[0])\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            playoff_wins1 = int(h2h_data[1].strip('[+]'))\n",
    "        # type error from NoneType, AttributeError from stripping '[+]'\n",
    "        except (TypeError, AttributeError): \n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            fusen_wins1 = int(h2h_data[2].strip('[-]'))\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            wins2 = int(h2h_data[3])\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            playoff_wins2 = int(h2h_data[4].strip('[+]'))\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            fusen_wins2 = int(h2h_data[5].strip('[-]'))\n",
    "        except (TypeError, AttributeError):\n",
    "            pass\n",
    "        \n",
    "    # initialize to minimum expected value\n",
    "    ID1_wins = wins1\n",
    "    ID2_wins = wins2\n",
    "\n",
    "    # check for nonetypes, else add playoff_wins and fusen_wins\n",
    "    if playoff_wins1 is not None:\n",
    "        ID1_wins += playoff_wins1\n",
    "    if fusen_wins1 is not None:\n",
    "        ID1_wins -= fusen_wins1\n",
    "\n",
    "    if playoff_wins2 is not None:\n",
    "        ID2_wins += playoff_wins2\n",
    "    if fusen_wins2 is not None:\n",
    "        ID2_wins -= fusen_wins2\n",
    "        \n",
    "    data_dict.update({u'ID1': ID1, u'shikona1': shikona1, u'ID2': ID2, u'shikona2': shikona2, \n",
    "                     u'ID1_wins': ID1_wins, u'ID2_wins': ID2_wins, u'flag': flag})\n",
    "    data_rows.append(data_dict)\n",
    "    \n",
    "# compile list of dicts into pandas dataframe\n",
    "cols = [u'ID1', u'shikona1', u'ID2', u'shikona2', u'ID1_wins', u'ID2_wins', u'flag']\n",
    "h2h_df = pd.DataFrame(data_rows, columns=cols)\n",
    "\n",
    "end = time.time()\n",
    "exec_time = end - start\n",
    "print \"\\n# --- SCRAPING DONE --- #\"\n",
    "print \"Execution Time: %.2f (s)\" % exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>shikona1</th>\n",
       "      <th>ID2</th>\n",
       "      <th>shikona2</th>\n",
       "      <th>ID1_wins</th>\n",
       "      <th>ID2_wins</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11878</td>\n",
       "      <td>Hakuho Sho</td>\n",
       "      <td>10693</td>\n",
       "      <td>Akiasahi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11878</td>\n",
       "      <td>Hakuho Sho</td>\n",
       "      <td>11078</td>\n",
       "      <td>Ako</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11878</td>\n",
       "      <td>Hakuho Sho</td>\n",
       "      <td>11754</td>\n",
       "      <td>Aminishiki</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11878</td>\n",
       "      <td>Hakuho Sho</td>\n",
       "      <td>11757</td>\n",
       "      <td>Aoiyama</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11878</td>\n",
       "      <td>Hakuho Sho</td>\n",
       "      <td>11490</td>\n",
       "      <td>Aran</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID1    shikona1    ID2    shikona2  ID1_wins  ID2_wins   flag\n",
       "0  11878  Hakuho Sho  10693    Akiasahi         1         0  False\n",
       "1  11878  Hakuho Sho  11078         Ako         0         1  False\n",
       "2  11878  Hakuho Sho  11754  Aminishiki        37         4  False\n",
       "3  11878  Hakuho Sho  11757     Aoiyama        17         0  False\n",
       "4  11878  Hakuho Sho  11490        Aran        12         0  False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2h_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Suginomori Ryuji - Aminishiki Ryuji'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rikishi_df.loc[11754, 'shikona']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
