"""Script to filter out the duplicate rows in raw head-to-head DataFrame generated by feature generation script.

Duplicate rows occur b/c the head-to-head data between sumo A and sumo B are stored twice, once on each sumo wrestler's
bout history. The order of information is merely swapped.

For example, Hakuho vs. Kakuryu as opposed to Kakuryu vs. Hakuho.

Usage:
(1) Set up pickle file from which to load head-to-head data (generated from scrape_multiple_h2h.py)
(2) Set up pickle file save name (bottom of script)
(3) Run filter_duplicates.py

"""

import time
import pandas as pd
pd.set_option('display.width', 500)
pd.set_option('display.max_columns', 100)

# --- Load Pickle File with Raw H2H DataFrame (with duplicates) --- #

h2h_df = pd.read_pickle('data/recent_full_h2h.pkl')

originals = []   # DataFrame labels that were used to check for duplicates
duplicates = []  # DataFrame labels of rows with duplicates

checkpoint1 = 0                  # where we left off
checkpoint2 = len(h2h_df.index)  # where we want to be

start = time.time()
for ind, row in h2h_df.iterrows():

    # watch out for this 'if' statement; the ind is the DataFrame label, NOT necessarily consecutive index
    if (ind >= checkpoint1) & (ind <= checkpoint2):
        print "# --- Row: # %2d " % ind + " --- #"

        # --- Check for Duplicates --- #
        # (1): iterate over each row in h2h_df
        # (2): identify rows with same information but swapped order
        # (3): mark relevant index to be dropped later if duplicate

        if ind not in duplicates:  # only continue of we have not stored the DataFrame label yet in duplicates

            # --- Extract H2H Data From Row --- #
            ID1 = row['ID1']
            ID2 = row['ID2']
            date = row['date']
            tourney_day = row['tourney_day']
            kimarite = row['kimarite']
            outcome1 = row['outcome1']
            outcome2 = row['outcome2']
            rank1 = row['rank1']
            rank2 = row['rank2']

            # filter for duplicate row
            logical = (h2h_df['ID1'] == ID2) & (h2h_df['ID2'] == ID1) & \
                      (h2h_df['outcome1'] == outcome2) & (h2h_df['outcome2'] == outcome1) & \
                      (h2h_df['date'] == date) & (h2h_df['tourney_day'] == tourney_day) & \
                      (h2h_df['kimarite'] == kimarite)

            dup_df = h2h_df[logical]  # returns the duplicate row

            if len(dup_df.index) == 1:
                dup_index = dup_df.index.values[0]
                print " Duplicates found: %2d" % dup_index

                originals.append(ind)         # append original row index
                duplicates.append(dup_index)  # append duplicate row index

            elif len(dup_df.index) > 1:
                raise Exception(" Multiple duplicates for some reason. Label: %2d?" % ind)

            else:
                print " No duplicates"

        else:
            print " Is already marked as duplicate"

    if ind > checkpoint2:
        break

end = time.time()
exec_time = end-start
print "Execution Time: %2.2f (s)" % exec_time


# ------- Delete Duplicate Rows --------- #
h2h_df.drop(duplicates, inplace=True)


# --- Save New H2H DataFrame (RENAME, or REWRITE OVER RAW DF) --- #
# h2h_df.to_pickle('data/recent_full_h2h.pkl')

